\documentclass[12pt,letterpaper,reqno]{amsart}
\usepackage{enumerate}
\usepackage[shortlabels]{enumitem}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage[normalem]{ulem}
\usepackage{titlesec,bbm, hyperref}
\usepackage{spverbatim} 
\usepackage{esvect}
\usepackage{geometry}
\geometry{letterpaper, portrait, margin=1in}

\newcommand{\C}{\mathbb C}

\begin{document}

\thispagestyle{empty}
\centerline{\Large Math 675 Homework 1}
\centerline{Sumanth Ravipati}
\centerline{8/28/2018}
\vspace{.25in}

\begin{enumerate}[1.]
\item Let $\{v_1, \ldots, v_m\}\subset \C^m$ be nonzero vectors such that $(v_i, v_j)=0$ when $i\neq j$. Show that the set $\{v_1, \ldots, v_m\}$ is linearly independent.
\begin{flushleft}
Proof by contradiction. Assume that the set is not linearly independent, then $\exists \, v_j$ that is a linear combination of the other vectors. Therefore, $v_j = \sum_{i\not=j}\alpha_i v_i$ for some $1 \leq j \leq m$. Taking the inner product with $v_j$ of both sides give us: $\langle v_j, v_j \rangle = \sum_{i\not=j}\langle \alpha_i v_i, v_j \rangle = \sum_{i\not=j}\alpha_i \langle v_i, v_j \rangle = \sum_{i\not=j}\alpha_i \cdot 0 = 0 \Rightarrow v_j = 0$. This is true since $\langle v_i, v_j \rangle =0$ when $i\neq j$. Since this would be true for any $1 \leq j \leq m$, the only solution would be the trivial one where $v_j = 0$, and it is given in the statement that all the vectors are nonzero. Thus, we have reached our desired contradiction and so the set of nonzero vectors $\{v_1, \ldots, v_m\}\subset \C^m$ is indeed linearly independent. $\Box$
\end{flushleft}
\item Let $\{v_1, \ldots, v_m\}\subset \C^m$ be a set of linearly independent vectors, and suppose that $w\in \C^m\setminus \operatorname{span}\{v_1, \ldots, v_m\}$.  Prove that the set $\{v_1, \ldots, v_m, w\}$ is linearly independent.
\begin{flushleft}
Since $w$ is not spanned by $\{v_1, \ldots, v_m\}$, no linear combination of the basis vectors will give us $w$. If $w$ is a linear combination of $\{v_1, \ldots, v_m\}$, then the set $\{v_1, \ldots, v_m, w\}$ is linearly dependent. We shall prove this via the contrapositive of the following Lemma: \newline
If $\{v_1, \ldots, v_m\}$ is linearly dependent and if $\{v_1, \ldots, v_{m-1}\}$ is linearly independent, then $v_m$ is a linear combination of $v_1, \ldots, v_{m-1}$. \newline
Proof. We are given that $\lambda_1v_1 + \ldots + \lambda_m v_m = 0$ where some $\lambda_i \not= 0$. If $\lambda_m = 0$, then some $\lambda_i \not=$ for $1 \leq i \leq m - 1$. The equation then becomes $\lambda_1v_1 + \ldots + \lambda_{m-1} v_{m-1} = 0$, which is contrary to the assumption that $\{v_1, \ldots, v_{m-1}\}$ is linearly independent. Therefore $\lambda_m \not= 0$. \newline
If $w \not\in \operatorname{span}\{v_1, \ldots, v_m\}$, then $\{v_1, \ldots, v_m, w\}$ is linearly independent. $\Box$
\end{flushleft}
\item Let $U, V\subset \C^m$ be two subspaces. Prove that
$$\dim(U+V)+\dim(U\cap V)=\dim U + \dim V.$$
\begin{flushleft}
Consider the function: $T:U \times V \to U+V$ defined by $T(u,v) = u - v$. When $U \cap V$, $T(u,v) = u -u = \vv{0}$. Therefore, $N(T) = U \cap V$. The Range of the function map is clearly $U + V$. Given that the $\dim (U\times V) = \dim U + \dim V$. The Rank-Nullity Theorem gives us that $\dim(U+V)+\dim(U\cap V)=\dim U + \dim V. \, \Box$ \newline
For a more rigorous proof see the one below:
\end{flushleft}
\begin{flushleft}
let $\langle A\rangle = \{w_1, \ldots, w_k\}$ be the basis for $U \cap V$, where $k = \dim (U \cap V)$. Since $(U \cap V) \subset U$, $\dim (U \cap V) = k \leq \dim U$. If we extend this same initial basis to be a basis for $U$, we get: $\langle U \rangle= \{w_1, \ldots, w_k, u_1, \ldots, u_m\}$, where $\dim U = k + m$. Similarly, if we extend the same initial basis to be a basis for $V$, we get: $C = \{w_1, \ldots, w_k, v_1, \ldots, v_n\}$, where $\dim V = k + n$. \newline
By definition, the space $U + V$ is generated by the basis $\{w_1, \ldots, w_k, u_1, \ldots, u_m\, v_1, \ldots, v_n\}$ which shows us that: $\dim (U + V) = k + m + n$. Since $k + m + n + k = (k + m) + (k + n)$, we have shown that $\dim(U+V)+\dim(U\cap V)=\dim U + \dim V. \, \Box$
\end{flushleft}
\item Let $A$ be an $m\times n$ matrix. Show that the null space and range of $A$ satisfy
$$\dim N(A)+\dim R(A)=n.$$
\begin{flushleft}
Let $A$ be an $m\times n$ matrix, let us consider $A'$ as the same matrix in echelon form. $R(A') = R(A)$ since only elementary row operations are used in the transformation. If there are $r$ non-zero rows in $A'$, the rank is $r$. In the equation $Ax = 0$, $x$ has $n$ components. Since $r \leq n$, $n-r$ of the variables are free, which is also equal to the nullity of $A$. Therefore $\dim N(A)+\dim R(A) = (n-r) + r = n. \, \Box$
\end{flushleft}
\item Let $A$ be an $m\times n$ matrix. Show that 
$$R(A)^\perp =N(A^*).$$
\begin{align}
    x \in R(A)^\perp &\Leftrightarrow \langle x, Ay \rangle = 0 \quad \forall y \in M_{m\times n} \label{eq:4}\\
    &\Leftrightarrow \langle A^*x, y \rangle = 0 \quad \forall y \in M_{m\times n}\label{eq:3}\\
    &\Leftrightarrow A^*x = 0\\
    &\Leftrightarrow x \in N(A^*)
\end{align}
\begin{flushleft}
(1) An inner product is 0 iff the vectors are orthogonal. \newline
(2) By the definition of an adjoint operator in the context of an inner product. \newline
(3) If $y = A^*x, \langle A*x, y \rangle = \langle A*x, A^*x \rangle = 0 \Leftrightarrow A*x = 0$. \newline
(4) By definition $x$ is in the null space of $A^*$.
$$ (\forall x: x \in R(A)^\perp \Leftrightarrow x \in N(A^*)) \Leftrightarrow R(A)^\perp = N(A^*) \quad \Box $$
\end{flushleft}
\end{enumerate}
\end{document}